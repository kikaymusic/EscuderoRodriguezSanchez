{
 "cells": [
  {
   "cell_type": "code",
   "id": "85013174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T18:37:37.076959900Z",
     "start_time": "2026-02-20T18:37:36.959655100Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "def setup_workdirectory(\n",
    "    repo_url=\"https://github.com/kikaymusic/EscuderoRodriguezSanchez.git\",\n",
    "    branch=\"dev\",\n",
    "    repo_name=\"EscuderoRodriguezSanchez\",\n",
    "    directoy_name=\"Entornos_Complejos\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Función para detectar si el código se está ejecutando en Google Colab o en local\n",
    "    y configurar el entorno de trabajo en consecuencia.\n",
    "    \"\"\"\n",
    "    # Detectamos si estamos en Google Colab\n",
    "    in_colab = \"google.colab\" in sys.modules\n",
    "\n",
    "    if in_colab:\n",
    "        print(\"Entorno detectado: Google Colab\")\n",
    "\n",
    "        # Definimos la ruta del repositorio en Colab\n",
    "        repo_path = f\"/content/{repo_name}\"\n",
    "\n",
    "        # Borramos el repositorio si ya existe para evitar conflictos\n",
    "        if os.path.exists(repo_path):\n",
    "            os.system(f\"rm -rf {repo_path}\")\n",
    "\n",
    "        # Clonamos la rama especificada del repositorio\n",
    "        os.system(f\"git clone -b {branch} --single-branch {repo_url}\")\n",
    "\n",
    "        # Cambiamos al directorio del repositorio\n",
    "        os.system(f\"%cd {repo_path}\")\n",
    "\n",
    "        # Añadimos el directorio especificado al path\n",
    "        sys.path.append(f'/content/{repo_name}/{directoy_name}')\n",
    "\n",
    "    else:\n",
    "        print(\"Entorno detectado: Local\")\n",
    "\n",
    "        # Añadir el directorio especificado al path de Python\n",
    "        notebook_dir = os.path.dirname(os.path.abspath('__file__')) if '__file__' in globals() else os.getcwd()\n",
    "        k_brazos_dir = notebook_dir if directoy_name in notebook_dir else os.path.join(notebook_dir, directoy_name)\n",
    "        if k_brazos_dir not in sys.path:\n",
    "            sys.path.insert(0, k_brazos_dir)\n",
    "\n",
    "\n",
    "setup_workdirectory()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno detectado: Local\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "54302a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T18:37:37.269549400Z",
     "start_time": "2026-02-20T18:37:37.086220700Z"
    }
   },
   "source": [
    "import gymnasium as gym"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entorno Blackjack para tipo Tabular (Espacio de estados discreto) off-policy\n",
    "\n",
    "En Off-policy, la Política de Comportamiento es distinta a la Política Objetivo. El agente genera experiencia moviéndose por el entorno de una forma (explorando mucho), pero actualiza sus valores asumiendo que está siguiendo una política completamente diferente (generalmente, una política 100% óptima o Greedy).\n",
    "\n",
    "En On-policy, la Política de Comportamiento es exactamente la misma que la Política Objetivo. El agente aprende el valor de la política que está utilizando actualmente para tomar decisiones."
   ],
   "id": "70a26c6810bdf4db"
  },
  {
   "cell_type": "code",
   "id": "0633b3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T18:37:37.320866200Z",
     "start_time": "2026-02-20T18:37:37.282021400Z"
    }
   },
   "source": [
    "from Entornos_Complejos.src.agents.montecarlo import AgentMonteCarlo\n",
    "from Entornos_Complejos.src.utils import SEMILLA\n",
    "from Entornos_Complejos.src.policies.epsilon_greedy import EpsilonGreedyPolicy\n",
    "\n",
    "# Siguiendo las reglas de Sutton & Barto\n",
    "env = gym.make(\"Blackjack-v1\", render_mode=\"rgb_array\", sab=True)\n",
    "\n",
    "# Inicializamos la política con la semilla\n",
    "behavior_policy = EpsilonGreedyPolicy(epsilon=0.1, n_actions=env.action_space.n, seed=SEMILLA)  # Política epsilon-greedy para el entrenamiento\n",
    "target_policy = EpsilonGreedyPolicy(epsilon=0.0, n_actions=env.action_space.n, seed=SEMILLA)  # Política full-greedy\n",
    "\n",
    "# El agente usa las políticas\n",
    "agent = AgentMonteCarlo(env, target_policy, behavior_policy)\n",
    "\n",
    "# Al iniciar el entrenamiento, le pasamos la semilla al entorno\n",
    "state, info = env.reset(seed=SEMILLA)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "268aa8567b1cc3a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
